> Container Orchestration Tool, developed by Google

- Tương đương Docker Swarm. Đảm bảo các container hoạt động trơn tru theo hướng dẫn theo file yaml.
- Sử dụng K8s khi:
	- Khi cty bạn đủ lớn, cần phải scaling hệ thống nhanh chóng, và đã sử dụng container (Docker).
	- Khi số lượng container đủ lớn cho các dịch vụ
	- Các dự án xác định cần scale hệ thống về sau
- K8s giải quyết:
	- Việc quản lý hàng loạt docker host
	- Container Scheduling
	- Rolling update
	- Scaling/Auto Scaling
	- Monitor vòng đời và tình trạng sống chết của container.
	- Self-hearing trong trường hợp có lỗi xãy ra. (Có khả năng phát hiện và tự correct lỗi)
	- Service discovery
	- Load balancing
	- Quản lý data, work node, log
	- Infrastructure as Code
	- Sự liên kết và mở rộng với các hệ thống khác
# K8s Architecture
![](https://i.imgur.com/A2zxalo.png)
2 phần chính:
- **Control Plane (Master Node):** Xử lý các tác vụ quản lý, điều khiển của hệ thống.
	- **etcd:** Là một cơ sở dữ liệu dạng key-value có tính khả dụng và đồng nhất cao. Etcd là nơi K8S lưu trữ toàn bộ các thông tin cấu hình của hệ thống
	- **controller:** Là một tiến trình chạy nền trên các Master Node. Các tiến trình này chạy liên tục để điều tiết trạng thái của hệ thống Kubernetes. Trong K8S, controller là một vòng lặp điều khiển giám sát trạng thái của cluster được chia sẻ qua qua các api và thực hiện các thay đổi cần thiết để chuyển trạng của cluster tới trạng thái mong muốn.
	- **kube api-server:** Đây là **core** của K8S Master, nó mở ra các HTTP API cho phép người dùng cuối cũng như các thành phần khác nhau trong chính K8S cluster có thể trao đổi thông tin với nhau. K8S API cho phép người dùng lấy thông tin về trạng thái của các đối tượng trong hệ thống như Pods, Namespaces, Services... Hầu hết các tác vụ sử dụng kube-api thông qua lệnh kubectl nhưng cũng có thể gọi trực tiếp REST API.
	- **kube-scheduler:** Đây là service mặc định của K8S làm nhiệm vụ phân phối Pod sẽ được chạy trên node nào. Mỗi Container bên trong Pod có thể có những yêu cầu khác nhau, hoặc ngay các Pod cũng có yêu cầu khác nhau. Do đó nhiệm vụ của Scheduler là tìm kiếm các node thỏa mãn các điều kiện trên và lựa chọn node tối ưu nhất để chạy. Tron trường hợp không có node nào thỏa mãn các điều kiện đặt ra thì Pod sẽ ở trạng thái chưa được lên lịch thực hiện cho tới khi Scheduler tìm được node phù hợp.
- **Data Plane (Worker Node):** Xử lý các work load của hệ thống. Các pod sẽ được tạo và chạy trên các Worker Node này.
	- **kubelet**: Nó đóng vai trò như một "Node Agent" của K8s trên các Worker Node. Nhiệm vụ của nó để Worker Node được đăng ký và quản lý bởi cụm K8S cũng như là nhận nhiệm vụ triển khai các Pod (thường thông qua kube api-server) và đảm báo các container đó chạy ổn định. Lưu ý là kubelete không quản lý các container không được tạo bởi Kubernetes
	- **kube-proxy**: Kube-proxy là một network proxy chạy trên mỗi node trong K8S cluster, thực hiện một phần Kubernetes Service. Kube-proxy duy trình network rules trên các node. Những network rules này cho phép kết nối mạng đến các pods từ trong hoặc ngoài cluster.
# How to run a pod on K8S?
Run 1 pod nginx:
```powershell
kubectl run --generator=run-pod/v1 nginx --image=nginx --restart="Always"
```
- Bước 1: `kubectl` $\rightarrow$ `api-server` $\rightarrow$ `etcd`
	- `kubectl` sẽ kết nối tới`kube api-server` và nói với `kube api-server` rằng tôi muốn tạo một Pod mới có tên là **nginx**.
	- `kube api-server` đã nhận thông tin yêu cầu, và việc tiếp theo nó sẽ thực hiện ghi thông tin yêu cầu đó vào `etcd`.
	- Khi ghi dữ liệu thành công vào etcd, `etcd` sẽ trả lời `api-server` và `api-server` trả về kết quả cho `kubectl` rằng pod đã được tạo (Pod created). 
	- Thực tế tại thời điểm này chưa có Pod nào được tạo cả.
- Bước 2: `scheduler` $\rightarrow$ `api-server`
	- `scheduler` sẽ định kỳ hỏi lại `api-server` có gì mới không. `api-server` sẽ trả lời `scheduler` rằng có một request tạo mới một Pod tên là **nginx** $\rightarrow$ `scheduler` lúc này sẽ thực hiện kiểm tra tất cả các node đang sẵn sàng và chọn ra một node tối ưu nhất (ví dụ node1) có thể chạy Pod trên và trả kết quả về cho `api-server`.
- Bước 3: `api-server` $\rightarrow$ `etcd`
	- Khi nhận được kết quả của `scheduler`, `api-server` sẽ ghi thông tin vào `etcd`, hiểu rằng Pod **nginx** sẽ cần được tạo trên node1.
- Bước 4: `kubelet` $\rightarrow$ `api-server`
	- `kubelet` định kỳ kết nối với `api-server` để cập nhật trạng thái node mà nó đang quản lý, trạng thái các Pod đang chạy trên node đó cũng như nhận các yêu cầu mới từ `api-server`. 
	- Hiểu đơn giản thì `kubelet` trao đổi với `api-server` 2 câu: "Hey `api-server` tao đang chạy 5 pod và tất cả đều đang running ok không có vấn đề gì cả, tao cũng đang sống khỏe" "Mày có việc gì mới cho tao không?" Lúc này `api-server` trả lời "Có, tao cần mày chạy một Pod mới với thông tin như thế này".
- Bước 5: `kubelet` $\rightarrow$ `CRI`
	- `kubelet` đã nhận thông tin từ `api-server`, nó làm việc với `CRI` (_CRI là viết tắt của cụm từ **Container Runtime Interface** đảm nhiệm vai trò duy trì hoạt động của container_) để tạo một Pod mới theo yêu cầu (`CRI` có thể là Docker hoặc ContainerD)
- Bước 6: `controller manager`
	- Giờ thì Pod đã được tạo xong, tuy nhiên lưu ý rằng trong lệnh tạo Pod ta đã set tham số **--restart="Always"** nghĩa là nếu Pod này vì lý do gì mà bị down thì cần phải tạo một Pod khác thay thế. Vậy làm sao để làm được việc đó? Câu trả lời là `controller manager`.
	- `Controller` định kỳ sẽ gọi `api-server` để biết trạng thái hiện tại (current state) và trạng thái mong muốn (desired state). Trạng thái mong muốn là có 1 Pod nginx chạy trên node1, còn hiện tại thì không có Pod **nginx** nào đang chạy $\rightarrow$ `Controller Manager` sẽ yêu cầu tạo lại Pod **nginx** để đảm bảo trạng thái hiện tại phải giống với trạng thái mong muốn.
# Monolith Architecture
![](https://i.imgur.com/W6EX9bv.png)
- Được sử dụng nhiều
- Tất cả chức năng bao gồm cả thư viện của bên thứ 3 đều được gộp chung vào 1 deployment ==> Các ứng dụng nhỏ thì ok, nhưng tốn nhiều thời gian do tất cả module phải đi cùng nhau. Nếu 1 module team này đã phát triển xong nhưng module khác chưa xong, ghép nối khó khăn. Khi mở rộng hoặc scale, phải update tất cả module ==> Rủi ro ==> Chuyển sang [[#Microservice Architecture]]
# Microservice Architecture
![](https://i.imgur.com/ukfHybH.png)
- Một chức năng lớn được chia thành các chức năng nhỏ hơn được gọi là service
- Khi scale chỉ cần update các service liên quan
- Giảm hiện tượng bottleneck

Một service cần chạy trên một machine ==> Có nhiều service thì số lượng machine tăng lên ==> Tốn kém ==> Container.
![](https://i.imgur.com/NZG2aHR.png)

Các service thay vì được chứa vào machine thì được đóng gói và chứa vào các container (Containerize Application (Docker))
Cần nâng cấp 1 app ==> Tắt container chứa app ==> Thời gian tắt container để nâng cấp đến lúc bật lại gọi là downtime.
Thông báo cho các container =>  K8S API (Orchestrator) sử dụng K8s Control Plane (không thể trực tiếp can thiệp vào từng container mà can thiệp container qua các pod) ==> Giao tiếp với các node ở salve node (mỗi node gồm nhiều pod, mỗi pod quản lý được 1 hoặc nhiều container)
![](https://i.imgur.com/YhIvoDg.png)

- Pod là đơn vị nhỏ nhất trong k8s
- Nhiều node trên slave node nhóm lại thành các cluster. Bên trong các cluster thì các container kết nối với nhau thông qua 1 địa chỉ IP được tạo ra từ 1 virtual network trong cluster (không thể connect vào, cần 1 số config như proxy)
- Config: Sử dụng file deployments.yml (như việc 1 nhà soạn nhạc gửi 1 tác phẩm âm nhạc cho nhạc trưởng thực hiện) ![](https://i.imgur.com/OVUFOLb.png)
- Nếu 1 container bị crashed, pod đó sẽ được restart và 1 pod khác được tái sinh gọi là phân thân (replicas) ==> Downtime giảm xuống

